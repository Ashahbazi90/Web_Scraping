{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure this directory exists or create it before running the script\n",
    "project_directory = \"/Users/aryasmc/My_USD/Year_2024/Summer_2024/Applied Text Mining (ADS-509-01)\"\n",
    "os.chdir(project_directory)\n",
    "\n",
    "# Create a lyrics directory if it doesn't exist\n",
    "lyrics_directory = os.path.join(project_directory, 'lyrics')\n",
    "if not os.path.exists(lyrics_directory):\n",
    "    os.makedirs(lyrics_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics Scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_artists_lyrics():\n",
    "    base_url = \"https://www.azlyrics.com\"\n",
    "    artists = {\n",
    "        'Robyn': 'r/robyn.html',\n",
    "        'Cher': 'c/cher.html'\n",
    "    }\n",
    "\n",
    "    def get_song_links(artist_url):\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "        response = requests.get(artist_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return [base_url + link.get('href') for link in soup.find_all('a', href=True)\n",
    "                if '/lyrics/' in link.get('href') and link.get('href').startswith('/lyrics/')][:25]\n",
    "\n",
    "    def scrape_lyrics(song_url):\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "        response = requests.get(song_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        lyrics_div = soup.find('div', class_=False, id=False)\n",
    "        return lyrics_div.get_text(strip=True) if lyrics_div else \"\"\n",
    "\n",
    "    for artist, extension in artists.items():\n",
    "        artist_url = f\"{base_url}/{extension}\"\n",
    "        song_links = get_song_links(artist_url)\n",
    "        artist_dir = os.path.join(lyrics_directory, artist)\n",
    "        os.makedirs(artist_dir, exist_ok=True)\n",
    "        for link in song_links:\n",
    "            lyrics = scrape_lyrics(link)\n",
    "            song_name = link.split('/')[-1].replace('.html', '.txt')\n",
    "            file_path = os.path.join(artist_dir, song_name)\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(lyrics)\n",
    "\n",
    "# Call the scraping function\n",
    "scrape_artists_lyrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Robyn we have 25 files.\n",
      "For Robyn we have roughly 5381 words, 1134 are unique.\n",
      "For Cher we have 25 files.\n",
      "For Cher we have roughly 4071 words, 1165 are unique.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_lyrics():\n",
    "    artist_folders = [f for f in os.listdir(lyrics_directory) if os.path.isdir(os.path.join(lyrics_directory, f))]\n",
    "\n",
    "    def words(text):\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    for artist in artist_folders:\n",
    "        artist_path = os.path.join(lyrics_directory, artist)\n",
    "        files = [f for f in os.listdir(artist_path) if f.endswith('.txt')]\n",
    "        print(f\"For {artist} we have {len(files)} files.\")\n",
    "        artist_words = []\n",
    "        for file in files:\n",
    "            with open(os.path.join(artist_path, file), 'r', encoding='utf-8') as f:\n",
    "                artist_words.extend(words(f.read()))\n",
    "        unique_words = len(set(artist_words))\n",
    "        print(f\"For {artist} we have roughly {len(artist_words)} words, {unique_words} are unique.\")\n",
    "\n",
    "# Call the evaluation function\n",
    "evaluate_lyrics()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
